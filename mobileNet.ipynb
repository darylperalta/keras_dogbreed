{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "8a7bff8d-c95a-4cfb-8c38-14ab989f769b",
    "_uuid": "4da5a3e7db32799ca0108576e469157094d23111",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv\n",
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "im_size = 120\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "num_samples = 10222\n",
    "\n",
    "num_class = 120\n",
    "steps_per_epoch = num_samples//batch_size\n",
    "\n",
    "print(steps_per_epoch)\n",
    "epochs = 2\n",
    "\n",
    "def data_gen(batch_size, image_size):\n",
    "    \n",
    "    df_train = pd.read_csv('../input/labels.csv')\n",
    "    \n",
    "    targets_series = pd.Series(df_train['breed'])\n",
    "    one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "\n",
    "\n",
    "    \n",
    "    fn = pd.Series(df_train['id'])\n",
    "\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "  \n",
    "   \n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            #index = np.random.choice(fn.shape[0],1)\n",
    "            index = randint(0,fn.shape[0]-1)\n",
    "            img = cv2.imread('../input/train/{}.jpg'.format(fn[index]))\n",
    "            x_train.append(cv2.resize(img,(image_size,image_size)))\n",
    "            label = one_hot_labels[index]\n",
    "            y_train.append(label)\n",
    "        y_train_raw = np.array(y_train, np.uint8)\n",
    "        x_train_raw = np.array(x_train, np.float32) / 255.\n",
    "        print(i)\n",
    "        yield x_train_raw, y_train_raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "decf1fdf-5a24-41cd-b9b3-d49825efec82",
    "_uuid": "0946091bb67a488a05f9e39e8dac432b485eb70a",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting`include_top=True`, `input_shape` should be (224, 224, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-276c881cd6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Can't download weights in the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m base_model = MobileNet(#weights='imagenet',\n\u001b[0;32m----> 4\u001b[0;31m     weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Add a new top layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/applications/mobilenet.py\u001b[0m in \u001b[0;36mMobileNet\u001b[0;34m(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes)\u001b[0m\n\u001b[1;32m    383\u001b[0m                                       \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                                       include_top=include_top or weights)\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mrow_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, include_top)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 raise ValueError('When setting`include_top=True`, '\n\u001b[0;32m--> 107\u001b[0;31m                                  '`input_shape` should be ' + str(default_shape) + '.')\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When setting`include_top=True`, `input_shape` should be (224, 224, 3)."
     ]
    }
   ],
   "source": [
    "# Create the base pre-trained model\n",
    "# Can't download weights in the kernel\n",
    "base_model = MobileNet(#weights='imagenet',\n",
    "    weights = 'imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "# Add a new top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(data_gen( batch_size=batch_size, image_size = im_size),\n",
    "                    steps_per_epoch=2,\n",
    "                    epochs=2, verbose =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c419742-1c6a-40c6-a26a-782836ee3641",
    "_uuid": "25ed4a3f9ce837128e3baa3e91bb0aee10e72ab8"
   },
   "source": [
    "Remember, accuracy is low here because we are not taking advantage of the pre-trained weights as they cannot be downloaded in the kernel. This means we are training the wights from scratch and I we have only run 1 epoch due to the hardware constraints in the kernel.\n",
    "\n",
    "Next we will make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = []\n",
    "    \n",
    "\n",
    "df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "for f in tqdm(df_test['id'].values):\n",
    "    img = cv2.imread('../input/test/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (im_size, im_size)))\n",
    " \n",
    "x_test  = np.array(x_test, np.float32) / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f72763e1-68b6-4e54-9b80-ff0f4f94aa28",
    "_uuid": "e8a63ce4e324f3e011b3de7fc459301337d1b8d0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0457a19d-0e26-4619-a3c8-78c71e7d41e6",
    "_uuid": "626b762d81d28ff77032658092d5bd9523b186b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(preds)\n",
    "# Set column names to those generated by the one-hot encoding earlier\n",
    "col_names = one_hot.columns.values\n",
    "sub.columns = col_names\n",
    "# Insert the column id from the sample_submission at the start of the data frame\n",
    "sub.insert(0, 'id', df_test['id'])\n",
    "sub.head(10358)\n",
    "df_test.to_csv('pred_vgg.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a4ed0f81-8675-4a10-8b19-2d3ef191afe2",
    "_uuid": "b72af806cbbdea33edd7f73d24dbe9b9cbaae805",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
